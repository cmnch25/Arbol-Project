{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imK-jHQUv2po",
        "outputId": "6128ce05-3f24-47a7-cd22-78a6158c3890"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision einops tqdm pytorch-lightning scikit-learn\n",
        "!git clone https://github.com/ucaswangls/EfficientSCI.git\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/content/EfficientSCI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKN86tLmw30c",
        "outputId": "e1199262-2824-4577-a16b-d7158936e262"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (2.5.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (25.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning) (0.15.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.12.15)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.12/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "fatal: destination path 'EfficientSCI' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64,expandable_segments:True\"\n",
        "\n",
        "import re\n",
        "import glob\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, Dataset, Subset\n",
        "from tqdm import tqdm\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import random\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "import os\n",
        "import imageio.v2 as imageio\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from cacti.models.efficientsci import EfficientSCI"
      ],
      "metadata": {
        "id": "dlXav5gsw-11"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "do_train = True\n",
        "do_eval = True\n",
        "retrain = False\n",
        "band = 1\n",
        "model_ckpt_path = f\"/content/drive/MyDrive/efficientSCI_finetuned_multiband.pth\"\n",
        "\n",
        "train_locs = ['bos', 'bozeman', 'carlinNev', 'la', 'dallas']\n",
        "test_loc = 'miami'\n",
        "patch_size = 100\n",
        "grid_size = 1\n",
        "batch_size = 1\n",
        "epochs = 15\n"
      ],
      "metadata": {
        "id": "e5x6fI2Nw-8L"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiBandCaseADataset(Dataset):\n",
        "    def __init__(self, samples, patch_size=100, grid_size=1, band_transform=None, use_blocks_for_training=True):\n",
        "        \"\"\"\n",
        "        samples: list of (loc, path)\n",
        "        band_transform: optional callable(b_idx, x_norm_band) -> x_norm_band (for band-specific tweaks)\n",
        "        \"\"\"\n",
        "        self.samples = samples\n",
        "        self.patch_size = patch_size\n",
        "        self.grid_size = grid_size\n",
        "        self.patches_per_block = grid_size ** 2\n",
        "        self.band_transform = band_transform\n",
        "        self.use_blocks_for_training = use_blocks_for_training\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples) * self.patches_per_block\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        block_idx = idx // self.patches_per_block\n",
        "        patch_idx = idx % self.patches_per_block\n",
        "\n",
        "        _, path = self.samples[block_idx]\n",
        "        d = np.load(path)\n",
        "\n",
        "        y_full = d[\"compressed\"].astype(np.float32)\n",
        "        phi_s_f = d[\"counts\"].astype(np.float32)\n",
        "        B, H, W = y_full.shape\n",
        "        T = int(len(d[\"target_times\"]))\n",
        "\n",
        "\n",
        "        if \"masks\" not in d: #make sure masks are there\n",
        "            raise KeyError(f\"{os.path.basename(path)} missing 'masks' ([B,T,H,W]). Re-save with save_masks=True.\")\n",
        "        phi_full = d[\"masks\"].astype(np.float32)\n",
        "\n",
        "\n",
        "        has_x = (\"blocks\" in d) and self.use_blocks_for_training\n",
        "        x_full = d[\"blocks\"].astype(np.float32) if has_x else np.zeros((B, T, H, W), dtype=np.float32)\n",
        "\n",
        "        #Make sure same patch across bands\n",
        "        ps  = self.patch_size\n",
        "        row = (patch_idx // self.grid_size) * ps\n",
        "        col = (patch_idx %  self.grid_size) * ps\n",
        "\n",
        "        y_patch= y_full[:,row:row+ps,col:col+ps]\n",
        "        phi_s= phi_s_f[:,row:row+ps,col:col+ps]\n",
        "        phi_patch = phi_full[:,:,row:row+ps,col:col+ps].copy()\n",
        "        x_patch= x_full[:,:,row:row+ps,col:col+ps]\n",
        "\n",
        "        #Measurement as forward-SUM (no NaNs)\n",
        "        y_patch_f = np.nan_to_num(y_patch, nan=0.0)\n",
        "        y_sum = y_patch_f * phi_s\n",
        "\n",
        "        #Reference from SUM (no nanmax on avg!)\n",
        "        ref= np.max(y_sum, axis=(1, 2))\n",
        "        ref= np.where(np.isfinite(ref) & (ref > 0), ref, 1e-8)\n",
        "        ref_bc = ref[:, None, None, None]\n",
        "\n",
        "        #Normalise\n",
        "        x_norm = np.nan_to_num(x_patch/ref_bc, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "        x_norm = np.log1p(np.clip(x_norm, 0, None))\n",
        "        y_norm = np.nan_to_num(y_sum / ref[:, None, None], nan=0.0)\n",
        "\n",
        "        phi_raw   = phi_patch.astype(np.float32)\n",
        "        phi_s_raw = phi_s.astype(np.float32)\n",
        "\n",
        "        #Tensors\n",
        "        y_t= torch.tensor(y_norm).unsqueeze(1).float()\n",
        "        phi_t = torch.tensor(phi_raw).float()\n",
        "        phi_s_t= torch.tensor(phi_s_raw).unsqueeze(1).float()\n",
        "        x_t = torch.tensor(x_norm).float()\n",
        "        max_val = torch.tensor(ref).float()\n",
        "\n",
        "        return y_t, phi_t, phi_s_t, x_t, max_val\n"
      ],
      "metadata": {
        "id": "6W8YvT0kw_A3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root = \"/content/drive/MyDrive/Folder/multiband_compressed_blocks_12hrs\"\n",
        "train_locs = ['bos', 'bozeman', 'carlinNev', 'la', 'dallas']\n",
        "test_loc   = 'miami'\n",
        "\n",
        "def list_npz(loc, recursive=True):\n",
        "    pattern = os.path.join(root, loc, \"**\", \"*.npz\") if recursive else os.path.join(root, loc, \"*.npz\")\n",
        "    files = sorted(glob.glob(pattern, recursive=recursive))\n",
        "    print(f\"[scan] {loc}: {len(files)} npz files (pattern: {pattern})\")\n",
        "    return files\n",
        "\n",
        "# Show subfolders present\n",
        "print(\"Subfolders under root:\", sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root,d))]))\n",
        "\n",
        "trainval_files = []\n",
        "for loc in train_locs:\n",
        "    trainval_files += [(loc, p) for p in list_npz(loc)]\n",
        "\n",
        "test_files = [(test_loc, p) for p in list_npz(test_loc)]\n",
        "\n",
        "train_files, val_files = train_test_split(trainval_files, test_size=0.2, random_state=42)\n",
        "print(f\"train:{len(train_files)} val:{len(val_files)} test:{len(test_files)}\")\n",
        "\n",
        "def skip_none_collate(batch):\n",
        "    batch = [b for b in batch if b is not None]\n",
        "    if not batch:\n",
        "        return None\n",
        "    return default_collate(batch)\n",
        "\n",
        "train_dataset = MultiBandCaseADataset(train_files, patch_size=100, grid_size=1, band_transform=None)\n",
        "val_dataset   = MultiBandCaseADataset(val_files,   patch_size=100, grid_size=1, band_transform=None)\n",
        "test_dataset  = MultiBandCaseADataset(test_files,  patch_size=100, grid_size=1, band_transform=None)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, num_workers=16, shuffle=True,  pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=1, num_workers=16, shuffle=False, pin_memory=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=1, num_workers=16, shuffle=False, pin_memory=True)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = EfficientSCI().to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQSyjJ86xWoc",
        "outputId": "cb8d6c64-3ee7-40f1-c1f4-b4de9eb41988"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subfolders under root: ['bos', 'bozeman', 'carlinNev', 'dallas', 'la', 'miami']\n",
            "[scan] bos: 200 npz files (pattern: /content/drive/MyDrive/Folder/multiband_compressed_blocks_12hrs/bos/**/*.npz)\n",
            "[scan] bozeman: 200 npz files (pattern: /content/drive/MyDrive/Folder/multiband_compressed_blocks_12hrs/bozeman/**/*.npz)\n",
            "[scan] carlinNev: 200 npz files (pattern: /content/drive/MyDrive/Folder/multiband_compressed_blocks_12hrs/carlinNev/**/*.npz)\n",
            "[scan] la: 200 npz files (pattern: /content/drive/MyDrive/Folder/multiband_compressed_blocks_12hrs/la/**/*.npz)\n",
            "[scan] dallas: 200 npz files (pattern: /content/drive/MyDrive/Folder/multiband_compressed_blocks_12hrs/dallas/**/*.npz)\n",
            "[scan] miami: 200 npz files (pattern: /content/drive/MyDrive/Folder/multiband_compressed_blocks_12hrs/miami/**/*.npz)\n",
            "train:800 val:200 test:200\n",
            "\n",
            "FILE: bos_block_000.npz\n",
            "  keys: ['compressed', 'band_ids', 'block_time', 'target_times', 'counts', 'masks', 'blocks']\n",
            "  compressed      shape=(5, 50, 50) dtype=float32\n",
            "  band_ids        shape=(5,) dtype=<U16\n",
            "  block_time      shape=() dtype=<U19\n",
            "  target_times    shape=(72,) dtype=datetime64[ns]\n",
            "  counts          shape=(5, 50, 50) dtype=uint16\n",
            "  masks           shape=(5, 72, 50, 50) dtype=uint8\n",
            "  blocks          shape=(5, 72, 50, 50) dtype=float32\n",
            "\n",
            "FILE: bos_block_001.npz\n",
            "  keys: ['compressed', 'band_ids', 'block_time', 'target_times', 'counts', 'masks', 'blocks']\n",
            "  compressed      shape=(5, 50, 50) dtype=float32\n",
            "  band_ids        shape=(5,) dtype=<U16\n",
            "  block_time      shape=() dtype=<U19\n",
            "  target_times    shape=(72,) dtype=datetime64[ns]\n",
            "  counts          shape=(5, 50, 50) dtype=uint16\n",
            "  masks           shape=(5, 72, 50, 50) dtype=uint8\n",
            "  blocks          shape=(5, 72, 50, 50) dtype=float32\n",
            "\n",
            "FILE: bos_block_002.npz\n",
            "  keys: ['compressed', 'band_ids', 'block_time', 'target_times', 'counts', 'masks', 'blocks']\n",
            "  compressed      shape=(5, 50, 50) dtype=float32\n",
            "  band_ids        shape=(5,) dtype=<U16\n",
            "  block_time      shape=() dtype=<U19\n",
            "  target_times    shape=(72,) dtype=datetime64[ns]\n",
            "  counts          shape=(5, 50, 50) dtype=uint16\n",
            "  masks           shape=(5, 72, 50, 50) dtype=uint8\n",
            "  blocks          shape=(5, 72, 50, 50) dtype=float32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y any NaN?: False\n",
            "phi_s min/max: 15.0 43.0\n",
            "y min/max: 0.03003046 1.0\n",
            "compressed min/max: 36.21957778930664 107.09478759765625\n",
            "counts min/max: 15.0 43.0\n",
            "MSE vs SUM: nan\n",
            "MSE vs AVG: nan\n",
            "compressed min/max: 9.679545402526855 75.48373413085938\n",
            "counts min/max: 15.0 40.0\n",
            "MSE vs SUM: nan\n",
            "MSE vs AVG: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized_mse(x_pred, x_true, phi_s):\n",
        "    return torch.sum((x_pred - x_true)**2) / (torch.sum(x_true**2) + 1e-8)\n",
        "\n",
        "def mixed_loss(pred, target, phi_s):\n",
        "    nmse = normalized_mse(pred, target, phi_s)\n",
        "    peak_weight = (target > 0.6).float() * 5.0 + 1.0  # Boost high-radiance pixels\n",
        "    weighted_mse = torch.mean(peak_weight * (pred - target)**2)\n",
        "    return nmse + weighted_mse  #weighted_mse for balance\n",
        "\n",
        "\n",
        "if do_train:\n",
        "  train_losses, val_losses = [], []\n",
        "  scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "  def run_training(epochs, lr, start_epoch=0):\n",
        "      best_val = float('inf')\n",
        "      best_state = None\n",
        "      lr_decay_factor = 0.5\n",
        "\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "      early_stop_patience = 30\n",
        "      no_improve_epochs = 0\n",
        "\n",
        "\n",
        "      for epoch in range(start_epoch, start_epoch + epochs):\n",
        "\n",
        "          torch.cuda.empty_cache()\n",
        "          gc.collect()\n",
        "          model.train()\n",
        "          total_train_loss = 0\n",
        "\n",
        "          for y, phi, phi_s, x, max_val in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}\"):\n",
        "            y, phi, phi_s, x, max_val = [t.squeeze(0).to(device) for t in (y, phi, phi_s, x, max_val)]\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                output = model(y, phi, phi_s)[0]\n",
        "                output = torch.nan_to_num(output, nan=0.0)\n",
        "                loss = mixed_loss(output, x, phi_s)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "          train_losses.append(total_train_loss / len(train_loader))\n",
        "\n",
        "          # Validation\n",
        "          model.eval()\n",
        "          total_val_loss = 0\n",
        "          with torch.no_grad():\n",
        "              for y, phi, phi_s, x, max_val in val_loader:\n",
        "                  y, phi, phi_s, x, max_val = [t.squeeze(0).to(device) for t in (y, phi, phi_s, x, max_val)]\n",
        "                  output = model(y, phi, phi_s)[0]\n",
        "                  output = torch.nan_to_num(output, nan=0.0)\n",
        "                  val_loss = mixed_loss(output, x, phi_s)\n",
        "                  total_val_loss += val_loss.item()\n",
        "\n",
        "                  if torch.isnan(output).any():\n",
        "                      print(\"NaNs in model output!\")\n",
        "                  if torch.isnan(x).any():\n",
        "                      print(\"NaNs in target x\")\n",
        "          val_losses.append(total_val_loss / len(val_loader))\n",
        "          # Save losses\n",
        "          np.save(\"train_losses.npy\", np.array(train_losses))\n",
        "          np.save(\"val_losses.npy\", np.array(val_losses))\n",
        "\n",
        "          if val_losses[-1] < best_val:\n",
        "            best_val = val_losses[-1]\n",
        "            best_state = model.state_dict().copy()\n",
        "            print(f'New Best Model at Epoch {epoch+1}')\n",
        "            torch.save(best_state, model_ckpt_path)\n",
        "            no_improve_epochs = 0\n",
        "\n",
        "          else:\n",
        "            no_improve_epochs += 1\n",
        "            print(f\"No improvement for {no_improve_epochs} epochs.\")\n",
        "\n",
        "          if (no_improve_epochs +1)% 20 ==0:\n",
        "            for param_goup in optimizer.param_groups:\n",
        "              param_group['lr'] *= lr_decay_factor\n",
        "\n",
        "          if no_improve_epochs >= early_stop_patience:\n",
        "            print('Early stopping occurred')\n",
        "            break\n",
        "\n",
        "          for param_group in optimizer.param_groups:\n",
        "            print(f\"[{epoch+1}] Train: {train_losses[-1]:.4f} | Val: {val_losses[-1]:.4f}| Learning rate: {param_group['lr']:.2e}\")\n",
        "\n",
        "          torch.cuda.empty_cache()\n",
        "          gc.collect()\n",
        "\n",
        "      return best_state, train_losses, val_losses\n",
        "\n",
        "  #Main training\n",
        "  if retrain:\n",
        "    model.load_state_dict(torch.load(model_ckpt_path))\n",
        "  best_model_state, train_losses, val_losses = run_training(epochs=300, lr=1e-4)\n",
        "\n",
        "  # Save best model\n",
        "  if best_model_state is not None:\n",
        "    torch.save(best_model_state, model_ckpt_path)\n",
        "    np.save(\"train_losses.npy\", np.array(train_losses))\n",
        "    np.save(\"val_losses.npy\", np.array(val_losses))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7KBXFCqfxnuK",
        "outputId": "1ffb70b9-f52d-4ba5-8d44-ef2e061c4449"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1112875603.py:39: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n",
            "Train Epoch 1:   0%|          | 0/800 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-1112875603.py:98: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Train Epoch 1: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 1\n",
            "[1] Train: 0.4087 | Val: 0.1481| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 2: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 2\n",
            "[2] Train: 0.1057 | Val: 0.0607| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 3: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 3\n",
            "[3] Train: 0.0650 | Val: 0.0492| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 4: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[4] Train: 0.0565 | Val: 0.0538| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 5: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[5] Train: 0.0529 | Val: 0.0614| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 6: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[6] Train: 0.0450 | Val: 0.0500| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 7: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 7\n",
            "[7] Train: 0.0458 | Val: 0.0417| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 8: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 8\n",
            "[8] Train: 0.0432 | Val: 0.0414| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 9: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 9\n",
            "[9] Train: 0.0411 | Val: 0.0397| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 10: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[10] Train: 0.0418 | Val: 0.0450| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 11: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[11] Train: 0.0388 | Val: 0.0399| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 12: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[12] Train: 0.0406 | Val: 0.0546| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 13: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[13] Train: 0.0443 | Val: 0.0565| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 14: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[14] Train: 0.0431 | Val: 0.0415| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 15: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 15\n",
            "[15] Train: 0.0406 | Val: 0.0384| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 16: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[16] Train: 0.0420 | Val: 0.0387| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 17: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 17\n",
            "[17] Train: 0.0399 | Val: 0.0373| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 18: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 18\n",
            "[18] Train: 0.0354 | Val: 0.0361| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 19: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 19\n",
            "[19] Train: 0.0358 | Val: 0.0355| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 20: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[20] Train: 0.0393 | Val: 0.0396| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 21: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 21\n",
            "[21] Train: 0.0391 | Val: 0.0354| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 22: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 22\n",
            "[22] Train: 0.0371 | Val: 0.0347| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 23: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[23] Train: 0.0340 | Val: 0.0371| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 24: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[24] Train: 0.0358 | Val: 0.0383| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 25: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[25] Train: 0.0388 | Val: 0.0362| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 26: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[26] Train: 0.0361 | Val: 0.0363| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 27: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[27] Train: 0.0337 | Val: 0.0368| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 28: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[28] Train: 0.0331 | Val: 0.0374| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 29: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 29\n",
            "[29] Train: 0.0328 | Val: 0.0341| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 30: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[30] Train: 0.0366 | Val: 0.0360| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 31: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[31] Train: 0.0353 | Val: 0.0352| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 32: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 32\n",
            "[32] Train: 0.0342 | Val: 0.0325| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 33: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[33] Train: 0.0320 | Val: 0.0386| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 34: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[34] Train: 0.0322 | Val: 0.0327| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 35: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 35\n",
            "[35] Train: 0.0311 | Val: 0.0325| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 36: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 36\n",
            "[36] Train: 0.0327 | Val: 0.0319| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 37: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[37] Train: 0.0366 | Val: 0.0328| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 38: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[38] Train: 0.0344 | Val: 0.0346| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 39: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[39] Train: 0.0326 | Val: 0.0324| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 40: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[40] Train: 0.0309 | Val: 0.0333| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 41: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 41\n",
            "[41] Train: 0.0310 | Val: 0.0316| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 42: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 42\n",
            "[42] Train: 0.0302 | Val: 0.0312| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 43: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[43] Train: 0.0324 | Val: 0.0372| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 44: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[44] Train: 0.0337 | Val: 0.0365| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 45: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[45] Train: 0.0327 | Val: 0.0329| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 46: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[46] Train: 0.0309 | Val: 0.0324| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 47: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[47] Train: 0.0305 | Val: 0.0315| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 48: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 48\n",
            "[48] Train: 0.0305 | Val: 0.0307| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 49: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[49] Train: 0.0299 | Val: 0.0357| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 50: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[50] Train: 0.0351 | Val: 0.0316| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 51: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[51] Train: 0.0328 | Val: 0.0315| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 52: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[52] Train: 0.0307 | Val: 0.0312| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 53: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[53] Train: 0.0297 | Val: 0.0321| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 54: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[54] Train: 0.0332 | Val: 0.0320| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 55: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 7 epochs.\n",
            "[55] Train: 0.0328 | Val: 0.0337| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 56: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 8 epochs.\n",
            "[56] Train: 0.0316 | Val: 0.0308| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 57: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 57\n",
            "[57] Train: 0.0294 | Val: 0.0303| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 58: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[58] Train: 0.0294 | Val: 0.0307| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 59: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[59] Train: 0.0297 | Val: 0.0304| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 60: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[60] Train: 0.0298 | Val: 0.0311| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 61: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 61\n",
            "[61] Train: 0.0298 | Val: 0.0299| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 62: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[62] Train: 0.0293 | Val: 0.0304| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 63: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[63] Train: 0.0321 | Val: 0.0325| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 64: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[64] Train: 0.0318 | Val: 0.0355| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 65: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[65] Train: 0.0310 | Val: 0.0300| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 66: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 66\n",
            "[66] Train: 0.0287 | Val: 0.0295| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 67: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[67] Train: 0.0286 | Val: 0.0299| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 68: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[68] Train: 0.0282 | Val: 0.0296| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 69: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[69] Train: 0.0288 | Val: 0.0299| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 70: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[70] Train: 0.0296 | Val: 0.0298| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 71: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[71] Train: 0.0291 | Val: 0.0310| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 72: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[72] Train: 0.0296 | Val: 0.0321| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 73: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 7 epochs.\n",
            "[73] Train: 0.0308 | Val: 0.0340| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 74: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 8 epochs.\n",
            "[74] Train: 0.0297 | Val: 0.0309| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 75: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 9 epochs.\n",
            "[75] Train: 0.0290 | Val: 0.0295| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 76: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 10 epochs.\n",
            "[76] Train: 0.0277 | Val: 0.0310| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 77: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 77\n",
            "[77] Train: 0.0279 | Val: 0.0286| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 78: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 78\n",
            "[78] Train: 0.0269 | Val: 0.0286| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 79: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[79] Train: 0.0269 | Val: 0.0290| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 80: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[80] Train: 0.0268 | Val: 0.0322| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 81: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[81] Train: 0.0282 | Val: 0.0308| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 82: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[82] Train: 0.0314 | Val: 0.0549| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 83: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[83] Train: 0.0303 | Val: 0.0291| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 84: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[84] Train: 0.0281 | Val: 0.0286| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 85: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 7 epochs.\n",
            "[85] Train: 0.0272 | Val: 0.0295| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 86: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 8 epochs.\n",
            "[86] Train: 0.0272 | Val: 0.0287| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 87: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 9 epochs.\n",
            "[87] Train: 0.0270 | Val: 0.0309| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 88: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 10 epochs.\n",
            "[88] Train: 0.0278 | Val: 0.0289| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 89: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 11 epochs.\n",
            "[89] Train: 0.0275 | Val: 0.0304| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 90: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 12 epochs.\n",
            "[90] Train: 0.0270 | Val: 0.0301| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 91: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 13 epochs.\n",
            "[91] Train: 0.0273 | Val: 0.0290| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 92: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 92\n",
            "[92] Train: 0.0268 | Val: 0.0281| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 93: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[93] Train: 0.0261 | Val: 0.0311| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 94: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[94] Train: 0.0276 | Val: 0.0299| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 95: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[95] Train: 0.0272 | Val: 0.0285| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 96: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 96\n",
            "[96] Train: 0.0266 | Val: 0.0281| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 97: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[97] Train: 0.0262 | Val: 0.0297| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 98: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[98] Train: 0.0274 | Val: 0.0294| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 99: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[99] Train: 0.0280 | Val: 0.0426| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 100: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[100] Train: 0.0287 | Val: 0.0303| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 101: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[101] Train: 0.0279 | Val: 0.0298| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 102: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[102] Train: 0.0264 | Val: 0.0291| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 103: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 103\n",
            "[103] Train: 0.0259 | Val: 0.0277| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 104: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[104] Train: 0.0258 | Val: 0.0279| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 105: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[105] Train: 0.0260 | Val: 0.0282| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 106: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[106] Train: 0.0262 | Val: 0.0321| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 107: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[107] Train: 0.0264 | Val: 0.0294| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 108: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[108] Train: 0.0263 | Val: 0.0293| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 109: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[109] Train: 0.0264 | Val: 0.0285| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 110: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 110\n",
            "[110] Train: 0.0251 | Val: 0.0276| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 111: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[111] Train: 0.0249 | Val: 0.0278| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 112: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[112] Train: 0.0270 | Val: 0.0305| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 113: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[113] Train: 0.0284 | Val: 0.0296| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 114: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[114] Train: 0.0273 | Val: 0.0304| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 115: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[115] Train: 0.0256 | Val: 0.0287| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 116: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[116] Train: 0.0253 | Val: 0.0281| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 117: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 117\n",
            "[117] Train: 0.0250 | Val: 0.0275| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 118: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[118] Train: 0.0244 | Val: 0.0275| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 119: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[119] Train: 0.0253 | Val: 0.0286| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 120: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[120] Train: 0.0259 | Val: 0.0279| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 121: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[121] Train: 0.0255 | Val: 0.0284| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 122: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[122] Train: 0.0244 | Val: 0.0278| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 123: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[123] Train: 0.0244 | Val: 0.0275| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 124: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 124\n",
            "[124] Train: 0.0240 | Val: 0.0273| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 125: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[125] Train: 0.0249 | Val: 0.0283| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 126: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[126] Train: 0.0258 | Val: 0.0300| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 127: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 3 epochs.\n",
            "[127] Train: 0.0282 | Val: 0.0290| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 128: 100%|██████████| 800/800 [06:29<00:00,  2.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 4 epochs.\n",
            "[128] Train: 0.0266 | Val: 0.0318| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 129: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 5 epochs.\n",
            "[129] Train: 0.0258 | Val: 0.0276| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 130: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 6 epochs.\n",
            "[130] Train: 0.0244 | Val: 0.0289| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 131: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 7 epochs.\n",
            "[131] Train: 0.0245 | Val: 0.0278| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 132: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New Best Model at Epoch 132\n",
            "[132] Train: 0.0238 | Val: 0.0273| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 133: 100%|██████████| 800/800 [06:29<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 1 epochs.\n",
            "[133] Train: 0.0243 | Val: 0.0303| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 134: 100%|██████████| 800/800 [06:28<00:00,  2.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No improvement for 2 epochs.\n",
            "[134] Train: 0.0269 | Val: 0.0286| Learning rate: 1.00e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train Epoch 135:  20%|██        | 161/800 [01:19<05:15,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1112875603.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    177\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mretrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m   \u001b[0mbest_model_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[0;31m# # Phase 2: Fine-tuning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1112875603.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(epochs, lr, start_epoch)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    357\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    358\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label='Training Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss (MSE)')\n",
        "plt.title('Training and Validation Loss per Epoch')\n",
        "plt.grid(False)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "np.save(\"/content/drive/MyDrive/train_losses.npy\", np.array(train_losses))\n",
        "np.save(\"/content/drive/MyDrive/val_losses.npy\", np.array(val_losses))"
      ],
      "metadata": {
        "id": "e2hoUxagxr1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if do_eval:\n",
        "    assert getattr(test_loader, 'batch_size', 1) == 1, \"Use batch_size=1 for path to batch zip.\"\n",
        "    SAVE_DIR = \"./recons\"; MAKE_GIFS = False\n",
        "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "    print(model_ckpt_path)\n",
        "    model.load_state_dict(torch.load(model_ckpt_path, map_location=\"cpu\"))\n",
        "    model.to(device).eval()\n",
        "\n",
        "    true_ts_all  = recon_ts_all = mse_lists = psnr_lists = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (y, phi, phi_s, x_true, max_val), (loc, path) in zip(test_loader, test_files):\n",
        "            y, phi, phi_s, x_true, max_val = [t.squeeze(0).to(device) for t in (y, phi, phi_s, x_true, max_val)]\n",
        "\n",
        "            with np.load(path, allow_pickle=True) as dmeta:\n",
        "              band_ids_raw = dmeta[\"band_ids\"]\n",
        "              band_ids = [str(b) for b in band_ids_raw.ravel()]\n",
        "              target_times = dmeta[\"target_times\"]\n",
        "            src_name = os.path.splitext(os.path.basename(path))[0]\n",
        "\n",
        "            # forward\n",
        "            x_pred = model(y, phi, phi_s)[0]\n",
        "\n",
        "            # invert log1p + per-band scaling\n",
        "            mv = max_val.view(-1, 1, 1, 1)\n",
        "            print(\"x_true raw range:\", float(x_true.min()), float(x_true.max()))\n",
        "            x_pred = torch.expm1(x_pred) * mv\n",
        "            x_true = torch.expm1(x_true) * mv\n",
        "\n",
        "            B, T, H, W = x_true.shape\n",
        "            h, w = H // 2, W // 2\n",
        "\n",
        "            if true_ts_all is None:\n",
        "                true_ts_all  = [[] for _ in range(B)]\n",
        "                recon_ts_all = [[] for _ in range(B)]\n",
        "                mse_lists = [[] for _ in range(B)]\n",
        "                psnr_lists = [[] for _ in range(B)]\n",
        "\n",
        "            mse_b = torch.mean((x_pred - x_true) ** 2, dim=(1, 2, 3))\n",
        "            max_true_b = x_true.view(B, -1).max(dim=1).values\n",
        "            psnr_b = 10.0 * torch.log10((max_true_b ** 2) / (mse_b + 1e-8))\n",
        "\n",
        "            for b in range(B):\n",
        "                mse_lists[b].append(mse_b[b].item())\n",
        "                psnr_lists[b].append(psnr_b[b].item())\n",
        "                true_ts_all[b].append(x_true[b, :, h, w].detach().cpu().numpy())\n",
        "                recon_ts_all[b].append(x_pred[b, :, h, w].detach().cpu().numpy())\n",
        "\n",
        "            # save recon + gt for this block\n",
        "            out_npz = os.path.join(SAVE_DIR, f\"{src_name}_recon.npz\")\n",
        "            np.savez_compressed(out_npz,x_pred=x_pred.detach().cpu().numpy().astype(np.float32),x_true=x_true.detach().cpu().numpy().astype(np.float32),band_ids=np.array(band_ids, dtype=\"U16\"),target_times=target_times)\n",
        "\n",
        "            torch.cuda.empty_cache(); gc.collect()\n",
        "\n",
        "    # concat series & plot\n",
        "    true_ts_concat  = [np.concatenate(chunks) for chunks in true_ts_all]\n",
        "    recon_ts_concat = [np.concatenate(chunks) for chunks in recon_ts_all]\n",
        "    start_time = datetime(2024, 4, 1)\n",
        "    n_frames = len(true_ts_concat[0])\n",
        "    frame_times = [start_time + timedelta(minutes=10 * i) for i in range(n_frames)]\n",
        "\n",
        "    # stacked per-band\n",
        "    import matplotlib.pyplot as plt\n",
        "    fig, axes = plt.subplots(len(true_ts_concat), 1, figsize=(14, 2.8 * len(true_ts_concat)), sharex=True)\n",
        "    if len(true_ts_concat) == 1: axes = [axes]\n",
        "    for b, ax in enumerate(axes):\n",
        "        ax.plot(frame_times, true_ts_concat[b], label=f\"Band {b+1} • True\")\n",
        "        ax.plot(frame_times, recon_ts_concat[b], '--', label=\"Recon\")\n",
        "        ax.grid(True, alpha=0.4); ax.legend(loc=\"upper right\"); ax.set_ylabel(\"Radiance\")\n",
        "    axes[-1].set_xlabel(\"Time\")\n",
        "    fig.suptitle(f\"Center-Pixel Time Series — stacked by band • Location: {test_loc}\")\n",
        "    fig.autofmt_xdate(); plt.tight_layout(); plt.show()\n",
        "\n",
        "    # single-axis “everything” plot\n",
        "    plt.figure(figsize=(14, 5))\n",
        "    for b in range(len(true_ts_concat)):\n",
        "        plt.plot(frame_times, true_ts_concat[b],  label=f\"B{b+1} True\")\n",
        "        plt.plot(frame_times, recon_ts_concat[b], '--', label=f\"B{b+1} Recon\")\n",
        "    plt.grid(True, alpha=0.4); plt.xlabel(\"Time\"); plt.ylabel(\"Radiance\")\n",
        "    plt.title(f\"All bands — True (solid) vs Recon (dashed) • {test_loc}\")\n",
        "    plt.gcf().autofmt_xdate(); plt.legend(ncol=2); plt.tight_layout(); plt.show()\n",
        "\n",
        "    # metrics\n",
        "    per_band_mse  = [float(np.mean(m)) for m in mse_lists]\n",
        "    per_band_psnr = [float(np.mean(p)) for p in psnr_lists]\n",
        "    print(\"\\nPer-band metrics:\")\n",
        "    for b in range(len(per_band_mse)):\n",
        "        print(f\"Band {b+1}: MSE={per_band_mse[b]:.6f} | PSNR={per_band_psnr[b]:.2f} dB\")\n",
        "    print(f\"Overall: MSE={np.mean(per_band_mse):.6f} | PSNR={np.mean(per_band_psnr):.2f} dB\")"
      ],
      "metadata": {
        "id": "1hUs22PwxyTL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}